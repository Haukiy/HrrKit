name: HRR Intake (Issues)

on:
  issues:
    types: [labeled]           # run only when a label is added
  issue_comment:
    types: [created]           # allow /process or /intake-commit re-runs
  workflow_dispatch:           # manual run from Actions UI

permissions:
  contents: write
  issues: write

jobs:
  run:
    # Run when:
    #  - issue is labeled 'hrr-intake'
    #  - someone comments '/process' or '/intake-commit'
    #  - manual dispatch
    if: >
      (github.event_name == 'issues' &&
       github.event.action == 'labeled' &&
       contains(join(github.event.issue.labels.*.name, ','), 'hrr-intake')) ||
      (github.event_name == 'issue_comment' && (
         startsWith(github.event.comment.body, '/process') ||
         startsWith(github.event.comment.body, '/intake-commit')
      )) ||
      (github.event_name == 'workflow_dispatch')

    runs-on: ubuntu-latest

    steps:
      - name: Checkout (with LFS)
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Debug event
        run: |
          echo "event:  ${{ github.event_name }}"
          echo "action: ${{ github.event.action }}"
          echo "labels: ${{ join(github.event.issue.labels.*.name, ',') }}"
          echo "title:  ${{ github.event.issue.title }}"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install numpy pandas matplotlib requests

      - name: Extract issue payload
        id: payload
        uses: actions/github-script@v7
        with:
          script: |
            const issue = context.payload.issue;
            core.setOutput('number', String(issue.number));
            core.setOutput('title', issue.title ?? '');
            core.setOutput('body', issue.body ?? '');
            core.setOutput('labels', (issue.labels ?? []).map(l => l.name).join(','));

      - name: Detect commit trigger from comment
        id: trig
        uses: actions/github-script@v7
        with:
          script: |
            const isComment = context.eventName === 'issue_comment';
            const body = isComment ? (context.payload.comment?.body || '') : '';
            const commitFromComment = isComment && body.trim().startsWith('/intake-commit');
            core.setOutput('commit_from_comment', commitFromComment ? 'true' : 'false');

      - name: Prepare raw_files, parse CSV from issue, pull files (attachments or inline), update database.csv
        env:
          ISSUE_BODY: ${{ steps.payload.outputs.body }}
          ISSUE_NUMBER: ${{ steps.payload.outputs.number }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e
          mkdir -p raw_files

          python - << 'PY'
          import os, re, sys, csv, io, pathlib, requests
          import pandas as pd

          body = os.environ.get("ISSUE_BODY","")
          issue_number = os.environ.get("ISSUE_NUMBER","" ).strip()
          run_id = os.environ.get("GITHUB_RUN_ID","" ).strip()
          TOKEN = os.environ.get("GITHUB_TOKEN","").strip()
          SUBMISSION_COL = "SubmissionKey"

          # ---------- Helpers ----------
          def find_csv_block(text: str) -> str:
              # Prefer fenced code block ```csv ... ```
              m = re.search(r"```(?:csv)?\s*([\s\S]*?)\s*```", text, flags=re.I)
              if m:
                  return m.group(1).strip()
              # Fallback: locate header anywhere, then collect CSV-looking lines
              lines = text.splitlines()
              canonical = "id,scource in ideee,time unit,energy unit,topic,filename"
              canonical_nospace = re.sub(r"\s+", "", canonical)
              start = None
              for i, line in enumerate(lines):
                  raw = line.strip().lower()
                  if not raw: continue
                  norm = re.sub(r"\s*,\s*", ",", raw)
                  if norm == canonical or re.sub(r"\s+", "", raw) == canonical_nospace:
                      start = i; break
              if start is None: return ""
              out = [re.sub(r"\s*,\s*", ",", lines[start].strip())]
              for j in range(start+1, len(lines)):
                  s = lines[j]
                  if not s.strip(): break
                  cnt = s.count(",")
                  if cnt >= 5 or (re.match(r"^\s*\d+\s*,", s) and cnt >= 5):
                      out.append(re.sub(r"\s*,\s*", ",", s.strip())); continue
                  if s.lstrip().startswith("[") or s.lstrip().startswith("http"): break
                  if s.lstrip().startswith("#") or "Notes (optional)" in s or "Attachments" in s: break
                  break
              return "\n".join(out).strip()

          def normalize_key(name: str) -> str:
              return re.sub(r"\s+", " ", name.strip().lower())

          def parse_structured_blocks(text: str):
              """Parse the block format from the issue template when CSV isn't provided."""
              key_map = {
                  "id": "ID",
                  "scource in ideee": "Scource in IDEEE",
                  "source in ideee": "Scource in IDEEE",
                  "topic": "Topic",
                  "filename (save as)": "Filename",
                  "filename save as": "Filename",
                  "filename": "Filename",
                  "time unit": "Time Unit",
                  "energy unit": "Energy Unit",
                  "attachment filename": "__attachment_hint__",
                  "attachment file name": "__attachment_hint__",
              }

              required = ["ID","Scource in IDEEE","Time Unit","Energy Unit","Topic","Filename"]
              rows = []
              current = {}

              def flush():
                  nonlocal current
                  if any(current.get(k) for k in required):
                      rows.append(current)
                  current = {}

              for line in text.splitlines():
                  stripped = line.strip()
                  if not stripped:
                      flush()
                      continue
                  if stripped.startswith("###") or stripped.startswith("**"):
                      continue
                  if ":" not in stripped:
                      continue
                  key, value = stripped.split(":", 1)
                  canonical = key_map.get(normalize_key(key))
                  if not canonical:
                      continue
                  if canonical == "ID" and current and any(current.values()):
                      flush()
                  current[canonical] = value.strip()
              flush()

              parsed = []
              for entry in rows:
                  if all(entry.get(k, "").strip() for k in required):
                      row = {k: entry.get(k, "").strip() for k in required}
                      row["__attachment_hint__"] = entry.get("__attachment_hint__", "").strip()
                      parsed.append(row)
              return parsed

          def extract_inline_files(text: str) -> dict:
              """
              Allow embedding raw files directly in the issue:
                ```csv filename=CAR_2010_Test01_raw.csv
                <content>
                ```
              or:
                ```text
                file: CAR_2010_Test01_raw.csv
                <content>
                ```
              """
              files = {}
              for m in re.finditer(r"```([^\n]*)\n([\s\S]*?)```", text):
                  info = (m.group(1) or "").strip()
                  content = m.group(2)
                  filename = None
                  mfn = re.search(r"filename\s*=\s*([^\s]+)", info, flags=re.I)
                  if mfn:
                      filename = mfn.group(1).strip()
                  if not filename:
                      first_line, *rest = content.splitlines()
                      mline = re.search(r"^\s*(?:#\s*)?file\s*:\s*(.+)$", first_line.strip(), flags=re.I)
                      if mline:
                          filename = mline.group(1).strip()
                          content = "\n".join(rest) + ("\n" if rest else "")
                  if filename:
                      files[pathlib.Path(filename).name] = content
              return files

          def download_with_auth(url: str, dest: pathlib.Path) -> bool:
              headers = {"Accept": "application/octet-stream", "User-Agent": "gh-actions-hrr-intake"}
              if TOKEN:
                  headers["Authorization"] = f"token {TOKEN}"
              for attempt_url in (url, url + "?download=1"):
                  try:
                      r = requests.get(attempt_url, headers=headers, allow_redirects=True, timeout=120)
                      if r.ok:
                          dest.parent.mkdir(parents=True, exist_ok=True)
                          with open(dest, "wb") as f: f.write(r.content)
                          return True
                  except Exception:
                      pass
              try:
                  r = requests.get(url, allow_redirects=True, timeout=120)
                  if r.ok:
                      dest.parent.mkdir(parents=True, exist_ok=True)
                      with open(dest, "wb") as f: f.write(r.content)
                      return True
              except Exception:
                  pass
              return False

          # ---------- Parse DB rows ----------
          csv_block = find_csv_block(body)
          rows = []
          if csv_block:
              csv_block = re.sub(r",\s+", ",", csv_block)
              rows = list(csv.DictReader(io.StringIO(csv_block)))
              if not rows:
                  print("CSV block parsed but contains no rows.", file=sys.stderr); sys.exit(1)
              for r in rows:
                  r["__attachment_hint__"] = ""
          else:
              rows = parse_structured_blocks(body)
              if not rows:
                  print("No CSV block or structured entry blocks found in issue body.", file=sys.stderr)
                  print("Body preview:", body[:300].replace("\n","\\n"), file=sys.stderr)
                  sys.exit(1)

          required = ["ID","Scource in IDEEE","Time Unit","Energy Unit","Topic","Filename"]
          missing = [h for h in required if h not in rows[0].keys()]
          if missing:
              print("CSV header mismatch. Need exactly:", ", ".join(required), file=sys.stderr)
              sys.exit(1)

          # ---------- Attachments + Inline file map ----------
          urls = re.findall(r"\((https?://[^\s)]+\.csv)\)", body, flags=re.I)
          attachments = []
          for u in urls:
              clean_url = u.strip()
              name = pathlib.Path(clean_url.split("?")[0]).name
              attachments.append({
                  "name": name,
                  "name_lower": name.lower(),
                  "url": clean_url,
                  "used": False,
              })

          def _find_attachment_by_name(name: str):
              if not name:
                  return None
              target = pathlib.Path(name).name.lower()
              for att in attachments:
                  if not att["used"] and att["name_lower"] == target:
                      return att
              return None

          def _take_next_unused_attachment():
              for att in attachments:
                  if not att["used"]:
                      return att
              return None

          def _download_attachment(att, dest: pathlib.Path) -> bool:
              if not att:
                  return False
              if download_with_auth(att["url"], dest):
                  att["used"] = True
                  return True
              return False

          inline_files = extract_inline_files(body)  # {"filename.csv": "content\n", ...}

          def clean_attachment_name(name: str) -> str:
              name = (name or "").strip()
              name = re.sub(r"\s*\(.*?\)\s*$", "", name)
              name = name.strip()
              return pathlib.Path(name).name if name else ""

          # ---------- Ensure database.csv ----------
          csv_path = pathlib.Path("database.csv")
          if csv_path.exists():
              df = pd.read_csv(csv_path)
          else:
              df = pd.DataFrame(columns=[
                  "ID","Scource in IDEEE","Time Unit","Energy Unit","Topic","Filename",
                  "ProcessedAt","Peak_kW","Area_kJ","UID","Concise ID", SUBMISSION_COL
              ])

          raw_dir = pathlib.Path("raw_files"); raw_dir.mkdir(parents=True, exist_ok=True)

          # ---------- For each row, ensure the raw file exists (download or inline) ----------
          for r in rows:
              for k in required:
                  if not str(r.get(k, "")).strip():
                      print(f"Missing field in CSV row: {k}", file=sys.stderr); sys.exit(1)

              desired = r["Filename"].strip()
              base = pathlib.Path(desired).name
              dest = raw_dir / desired
              attachment_hint = clean_attachment_name(r.get("__attachment_hint__", ""))

              have = False
              att = _find_attachment_by_name(base)
              if att:
                  print(f"Attempting download '{att['name']}' -> {dest}")
                  have = _download_attachment(att, dest)

              if not have and attachment_hint:
                  hint_base = pathlib.Path(attachment_hint).name
                  att = _find_attachment_by_name(hint_base)
                  if att:
                      print(f"Attempting download via attachment hint '{hint_base}' -> {dest}")
                      have = _download_attachment(att, dest)

              if not have and base in inline_files:
                  print(f"Writing inline file -> {dest}")
                  dest.parent.mkdir(parents=True, exist_ok=True)
                  with open(dest, "w", newline="") as f:
                      f.write(inline_files[base])
                  have = True

              if not have:
                  att = _take_next_unused_attachment()
                  if att:
                      print(f"No attachment name match for row ID {r['ID']} - using '{att['name']}' by submission order -> {dest}")
                      have = _download_attachment(att, dest)

              r.pop("__attachment_hint__", None)

              if not have:
                  print(f"Could not obtain '{desired}'.", file=sys.stderr)
                  print("Either attach the CSV or embed it as a code block like:", file=sys.stderr)
                  print("```csv filename=" + base + "\\n<your csv content>\\n```", file=sys.stderr)
                  sys.exit(1)

          # ---------- Append/update DB rows ----------
          if SUBMISSION_COL not in df.columns:
              df[SUBMISSION_COL] = pd.Series(dtype="string")
          elif str(df[SUBMISSION_COL].dtype) != "string":
              df[SUBMISSION_COL] = df[SUBMISSION_COL].astype("string")

          if not {"ProcessedAt","Peak_kW","Area_kJ","UID","Concise ID"}.issubset(df.columns):
              for c in ["ProcessedAt","UID","Concise ID"]:
                  if c not in df.columns: df[c] = pd.Series(dtype="string")
              for c in ["Peak_kW","Area_kJ"]:
                  if c not in df.columns: df[c] = pd.Series(dtype="float64")

          # Submission keys ensure reruns of the same issue rows update instead of duplicating
          if issue_number:
              prefix = f"issue-{issue_number}"
          elif run_id:
              prefix = f"run-{run_id}"
          else:
              prefix = "manual"

          prepared_rows = []
          for idx, r in enumerate(rows, start=1):
              r = dict(r)
              r[SUBMISSION_COL] = f"{prefix}-row-{idx}"
              prepared_rows.append(r)

          existing_keys = set(
              key
              for key in (
                  str(val).strip()
                  for val in df[SUBMISSION_COL].astype(str).tolist()
              )
              if key and key.lower() != "nan"
          )

          to_add = []
          for r in prepared_rows:
              key = str(r.get(SUBMISSION_COL,"" )).strip()
              if key and key in existing_keys:
                  mask = (df[SUBMISSION_COL] == key)
                  for k in ["ID","Scource in IDEEE","Time Unit","Energy Unit","Topic","Filename"]:
                      df.loc[mask, k] = r[k]
              else:
                  to_add.append(r)
                  if key:
                      existing_keys.add(key)

          if to_add:
              df = pd.concat([df, pd.DataFrame(to_add)], ignore_index=True)

          df.to_csv(csv_path, index=False)
          PY

      - name: Run HRR processor
        run: |
          python - << 'PY'
          import os, subprocess, sys
          import matplotlib; matplotlib.use("Agg")
          script = (
            'hrr_chat.py' if os.path.exists('hrr_chat.py')
            else ('hrrkit_excel.py' if os.path.exists('hrrkit_excel.py') else None)
          )
          if not script:
            print("Error: neither hrr_chat.py nor hrrkit_excel.py found", file=sys.stderr)
            sys.exit(1)
          sys.exit(subprocess.call([sys.executable, script,
            "--database","database.csv","--raw","raw_files","--base","hrr_database","--quantile","0.90"]))
          PY

      - name: Ensure output dir for artifact
        run: mkdir -p hrr_database

      - name: Upload outputs (artifact)
        uses: actions/upload-artifact@v4
        with:
          name: hrr-outputs-issue-${{ steps.payload.outputs.number }}
          path: |
            hrr_database/**
            database.csv
          if-no-files-found: warn
          retention-days: 10

      - name: Commit changes (only when comment is /intake-commit)
        if: ${{ steps.trig.outputs.commit_from_comment == 'true' }}
        shell: bash
        run: |
          set -e
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --global --add safe.directory "$GITHUB_WORKSPACE"

          if [ -n "$(git status --porcelain)" ]; then
            git add -A
            git commit -m "HRR intake (issue #${{ steps.payload.outputs.number }}): processed inputs [skip ci]"
            git push
          else
            echo "No changes to commit."
          fi

      - name: Comment result on issue
        uses: actions/github-script@v7
        with:
          script: |
            const num = Number('${{ steps.payload.outputs.number }}');
            const artifactName = `hrr-outputs-issue-${num}`;
            const commitTriggered = '${{ steps.trig.outputs.commit_from_comment }}' === 'true';
            const lines = [
              'âœ… HRR intake check completed.',
              '',
              `- Results attached as workflow artifact: **${artifactName}**`,
              commitTriggered
                ? '- Outputs were committed to the repository.'
                : '- To commit these results to the repository, comment: **`/intake-commit`**',
              '',
              'Re-run this check by commenting: **`/process`**'
            ];
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: num,
              body: lines.join('\n')
            });
