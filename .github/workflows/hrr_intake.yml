name: HRR Intake (Issues)

on:
  issues:
    types: [labeled]           # run only when a label is added
  issue_comment:
    types: [created]           # allow /validate or /intake-commit re-runs
  workflow_dispatch:           # manual run from Actions UI
    inputs:
      mode:
        description: "Run mode: validation or process"
        required: false
        default: validation

permissions:
  contents: write
  issues: write

jobs:
  run:
    # Run when:
    #  - issue is labeled 'hrr-intake'
    #  - someone comments '/process' or '/intake-commit'
    #  - manual dispatch
    if: >
      (github.event_name == 'issues' &&
       github.event.action == 'labeled' &&
       contains(join(github.event.issue.labels.*.name, ','), 'hrr-intake')) ||
      (github.event_name == 'issue_comment' && (
         startsWith(github.event.comment.body, '/process') ||
         startsWith(github.event.comment.body, '/validate') ||
         startsWith(github.event.comment.body, '/intake-commit')
      )) ||
      (github.event_name == 'workflow_dispatch')

    runs-on: ubuntu-latest

    steps:
      - name: Checkout (with LFS)
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Debug event
        run: |
          echo "event:  ${{ github.event_name }}"
          echo "action: ${{ github.event.action }}"
          echo "labels: ${{ join(github.event.issue.labels.*.name, ',') }}"
          echo "title:  ${{ github.event.issue.title }}"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install numpy pandas matplotlib requests

      - name: Extract issue payload
        id: payload
        uses: actions/github-script@v7
        with:
          script: |
            const issue = context.payload.issue;
            core.setOutput('number', String(issue.number));
            core.setOutput('title', issue.title ?? '');
            core.setOutput('body', issue.body ?? '');
            core.setOutput('labels', (issue.labels ?? []).map(l => l.name).join(','));

      - name: Determine run mode
        id: mode
        uses: actions/github-script@v7
        with:
          script: |
            const event = context.eventName;
            let mode = 'validation';
            if (event === 'issue_comment') {
              const body = (context.payload.comment?.body || '').trim();
              if (body.startsWith('/intake-commit')) {
                mode = 'process';
              } else {
                mode = 'validation';
              }
            } else if (event === 'workflow_dispatch') {
              const inputMode = (core.getInput('mode') || 'validation').trim().toLowerCase();
              if (inputMode === 'process') {
                mode = 'process';
              }
            }
            core.setOutput('mode', mode);

      - name: Require successful validation label before processing
        if: ${{ steps.mode.outputs.mode == 'process' }}
        uses: actions/github-script@v7
        with:
          script: |
            const issueNumber = Number('${{ steps.payload.outputs.number }}');
            const labelName = 'hrr-validated';
            const { data: issue } = await github.rest.issues.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
            });
            const hasLabel = (issue.labels || []).some(label => label.name === labelName);
            if (!hasLabel) {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: '⚠️ Validation has not passed yet. Comment **`/validate`** to run Phase 1 before requesting `/intake-commit`. '
              });
              core.setFailed(`Issue #${issueNumber} is missing the '${labelName}' label.`);
            }

      - name: Prepare raw_files, parse CSV from issue, pull files (attachments or inline), update database.csv
        env:
          ISSUE_BODY: ${{ steps.payload.outputs.body }}
          ISSUE_NUMBER: ${{ steps.payload.outputs.number }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e
          mkdir -p raw_files

          python - << 'PY'
          import os, re, sys, csv, io, pathlib, requests, hashlib
          import pandas as pd

          body = os.environ.get("ISSUE_BODY","")
          issue_number = os.environ.get("ISSUE_NUMBER","" ).strip()
          run_id = os.environ.get("GITHUB_RUN_ID","" ).strip()
          TOKEN = os.environ.get("GITHUB_TOKEN","").strip()
          SUBMISSION_COL = "SubmissionKey"

          # ---------- Helpers ----------
          def find_csv_block(text: str) -> str:
              # Prefer fenced code block ```csv ... ```
              m = re.search(r"```(?:csv)?\s*([\s\S]*?)\s*```", text, flags=re.I)
              if m:
                  return m.group(1).strip()
              # Fallback: locate header anywhere, then collect CSV-looking lines
              lines = text.splitlines()
              canonical_headers = [
                  "id,scource in ideee,time unit,energy unit,topic",
                  "id,scource in ideee,time unit,energy unit,topic,attachment filename",
                  "id,scource in ideee,time unit,energy unit,topic,filename",
              ]
              canonical_nospace = [re.sub(r"\s+", "", header) for header in canonical_headers]
              start = None
              for i, line in enumerate(lines):
                  raw = line.strip().lower()
                  if not raw:
                      continue
                  norm = re.sub(r"\s*,\s*", ",", raw)
                  nospace = re.sub(r"\s+", "", raw)
                  if norm in canonical_headers or nospace in canonical_nospace:
                      start = i
                      break
              if start is None:
                  return ""
              out = [re.sub(r"\s*,\s*", ",", lines[start].strip())]
              for j in range(start+1, len(lines)):
                  s = lines[j]
                  if not s.strip(): break
                  cnt = s.count(",")
                  if cnt >= 5 or (re.match(r"^\s*\d+\s*,", s) and cnt >= 5):
                      out.append(re.sub(r"\s*,\s*", ",", s.strip())); continue
                  if s.lstrip().startswith("[") or s.lstrip().startswith("http"): break
                  if s.lstrip().startswith("#") or "Notes (optional)" in s or "Attachments" in s: break
                  break
              return "\n".join(out).strip()

          def normalize_key(name: str) -> str:
              return re.sub(r"\s+", " ", name.strip().lower())

          def parse_structured_blocks(text: str):
              """Parse the block format from the issue template when CSV isn't provided."""
              key_map = {
                  "id": "ID",
                  "scource in ideee": "Scource in IDEEE",
                  "source in ideee": "Scource in IDEEE",
                  "topic": "Topic",
                  "filename (save as)": "Filename",
                  "filename save as": "Filename",
                  "filename": "Filename",
                  "time unit": "Time Unit",
                  "energy unit": "Energy Unit",
                  "attachment filename": "__attachment_hint__",
                  "attachment file name": "__attachment_hint__",
              }

              required = ["ID","Scource in IDEEE","Time Unit","Energy Unit","Topic"]
              rows = []
              current = {}

              def flush():
                  nonlocal current
                  if any(current.get(k) for k in required):
                      rows.append(current)
                  current = {}

              for line in text.splitlines():
                  stripped = line.strip()
                  if not stripped:
                      flush()
                      continue
                  if stripped.startswith("###") or stripped.startswith("**"):
                      continue
                  if ":" not in stripped:
                      continue
                  key, value = stripped.split(":", 1)
                  canonical = key_map.get(normalize_key(key))
                  if not canonical:
                      continue
                  if canonical == "ID" and current and any(current.values()):
                      flush()
                  current[canonical] = value.strip()
              flush()

              parsed = []
              for entry in rows:
                  if all(entry.get(k, "").strip() for k in required):
                      row = {k: entry.get(k, "").strip() for k in required}
                      row["__attachment_hint__"] = entry.get("__attachment_hint__", "").strip()
                      parsed.append(row)
              return parsed

          def extract_inline_files(text: str) -> dict:
              """
              Allow embedding raw files directly in the issue:
                ```csv filename=CAR_2010_Test01_raw.csv
                <content>
                ```
              or:
                ```text
                file: CAR_2010_Test01_raw.csv
                <content>
                ```
              """
              files = {}
              for m in re.finditer(r"```([^\n]*)\n([\s\S]*?)```", text):
                  info = (m.group(1) or "").strip()
                  content = m.group(2)
                  filename = None
                  mfn = re.search(r"filename\s*=\s*([^\s]+)", info, flags=re.I)
                  if mfn:
                      filename = mfn.group(1).strip()
                  if not filename:
                      first_line, *rest = content.splitlines()
                      mline = re.search(r"^\s*(?:#\s*)?file\s*:\s*(.+)$", first_line.strip(), flags=re.I)
                      if mline:
                          filename = mline.group(1).strip()
                          content = "\n".join(rest) + ("\n" if rest else "")
                  if filename:
                      files[pathlib.Path(filename).name] = content
              return files

          def download_with_auth(url: str, dest: pathlib.Path) -> bool:
              headers = {"Accept": "application/octet-stream", "User-Agent": "gh-actions-hrr-intake"}
              if TOKEN:
                  headers["Authorization"] = f"token {TOKEN}"
              for attempt_url in (url, url + "?download=1"):
                  try:
                      r = requests.get(attempt_url, headers=headers, allow_redirects=True, timeout=120)
                      if r.ok:
                          dest.parent.mkdir(parents=True, exist_ok=True)
                          with open(dest, "wb") as f: f.write(r.content)
                          return True
                  except Exception:
                      pass
              try:
                  r = requests.get(url, allow_redirects=True, timeout=120)
                  if r.ok:
                      dest.parent.mkdir(parents=True, exist_ok=True)
                      with open(dest, "wb") as f: f.write(r.content)
                      return True
              except Exception:
                  pass
              return False

          # ---------- Parse DB rows ----------
          csv_block = find_csv_block(body)
          rows = []
          if csv_block:
              csv_block = re.sub(r",\s+", ",", csv_block)
              raw_rows = list(csv.DictReader(io.StringIO(csv_block)))
              if not raw_rows:
                  print("CSV block parsed but contains no rows.", file=sys.stderr); sys.exit(1)
              csv_key_map = {
                  "id": "ID",
                  "scource in ideee": "Scource in IDEEE",
                  "source in ideee": "Scource in IDEEE",
                  "topic": "Topic",
                  "time unit": "Time Unit",
                  "energy unit": "Energy Unit",
                  "filename": "Filename",
                  "filename (save as)": "Filename",
                  "attachment filename": "__attachment_hint__",
                  "attachment file name": "__attachment_hint__",
              }
              rows = []
              for raw in raw_rows:
                  normalized = {"__attachment_hint__": ""}
                  for key, value in raw.items():
                      if key is None:
                          continue
                      canonical = csv_key_map.get(key.strip().lower())
                      target_key = canonical or key.strip()
                      normalized[target_key] = (value or "").strip()
                  rows.append(normalized)
          else:
              rows = parse_structured_blocks(body)
              if not rows:
                  print("No CSV block or structured entry blocks found in issue body.", file=sys.stderr)
                  print("Body preview:", body[:300].replace("\n","\\n"), file=sys.stderr)
                  sys.exit(1)

          required = ["ID","Scource in IDEEE","Time Unit","Energy Unit","Topic"]
          missing = [h for h in required if h not in rows[0].keys()]
          if missing:
              print("CSV header mismatch. Need exactly:", ", ".join(required), file=sys.stderr)
              sys.exit(1)

          # ---------- Attachments + Inline file map ----------
          urls = re.findall(r"\((https?://[^\s)]+\.csv)\)", body, flags=re.I)
          attachments = []
          for u in urls:
              clean_url = u.strip()
              name = pathlib.Path(clean_url.split("?")[0]).name
              attachments.append({
                  "name": name,
                  "name_lower": name.lower(),
                  "url": clean_url,
                  "used": False,
              })

          def _find_attachment_by_name(name: str):
              if not name:
                  return None
              target = pathlib.Path(name).name.lower()
              for att in attachments:
                  if not att["used"] and att["name_lower"] == target:
                      return att
              return None

          def _take_next_unused_attachment():
              for att in attachments:
                  if not att["used"]:
                      return att
              return None

          def _download_attachment(att, dest: pathlib.Path) -> bool:
              if not att:
                  return False
              if download_with_auth(att["url"], dest):
                  att["used"] = True
                  return True
              return False

          inline_files = extract_inline_files(body)  # {"filename.csv": "content\n", ...}
          inline_used = {name: False for name in inline_files.keys()}

          def clean_attachment_name(name: str) -> str:
              name = (name or "").strip()
              name = re.sub(r"\s*\(.*?\)\s*$", "", name)
              name = name.strip()
              return pathlib.Path(name).name if name else ""

          def _take_next_unused_inline():
              for nm, used in inline_used.items():
                  if not used:
                      inline_used[nm] = True
                      return nm
              return None

          def slugify_for_filename(value: str, fallback: str) -> str:
              cleaned = re.sub(r"[^a-z0-9]+", "-", (value or "").lower()).strip("-")
              return cleaned or fallback

          def canonical_filename(issue_seed: str, row_idx: int, topic: str, row_id: str,
                                  source_name: str, time_unit: str, energy_unit: str) -> str:
              topic_slug = slugify_for_filename(topic, "topic")[:40]
              row_slug = slugify_for_filename(row_id, f"row{row_idx}")[:40]
              ext = pathlib.Path(source_name or "").suffix.lower()
              if ext not in (".csv", ".txt"):
                  ext = ".csv"
              seed = "|".join([
                  issue_seed or "manual",
                  str(row_idx),
                  topic_slug,
                  row_slug,
                  (time_unit or "").strip().lower(),
                  (energy_unit or "").strip().lower(),
                  (source_name or "").strip().lower(),
              ])
              digest = hashlib.sha256(seed.encode("utf-8", "ignore")).hexdigest()[:10]
              return f"{topic_slug}_{row_slug}_{digest}_raw{ext}"

          # ---------- Ensure database.csv ----------
          csv_path = pathlib.Path("database.csv")
          if csv_path.exists():
              df = pd.read_csv(csv_path)
          else:
              df = pd.DataFrame(columns=[
                  "ID","Scource in IDEEE","Time Unit","Energy Unit","Topic","Filename",
                  "ProcessedAt","Peak_kW","Area_kJ","UID","Concise ID", SUBMISSION_COL
              ])

          raw_dir = pathlib.Path("raw_files"); raw_dir.mkdir(parents=True, exist_ok=True)

          issue_seed = issue_number or run_id or "manual"

          # ---------- For each row, ensure the raw file exists (download or inline) ----------
          for idx, r in enumerate(rows, start=1):
              for k in required:
                  if not str(r.get(k, "")).strip():
                      print(f"Missing field in CSV row: {k}", file=sys.stderr); sys.exit(1)

              attachment_hint = clean_attachment_name(r.get("__attachment_hint__", ""))
              chosen_inline_name = None
              chosen_attachment = None

              if attachment_hint and attachment_hint in inline_files and not inline_used.get(attachment_hint):
                  inline_used[attachment_hint] = True
                  chosen_inline_name = attachment_hint
              elif attachment_hint:
                  att = _find_attachment_by_name(attachment_hint)
                  if att:
                      chosen_attachment = att

              if not chosen_inline_name and not chosen_attachment:
                  att = _take_next_unused_attachment()
                  if att:
                      chosen_attachment = att

              if not chosen_inline_name and not chosen_attachment:
                  fallback_inline = _take_next_unused_inline()
                  if fallback_inline:
                      chosen_inline_name = fallback_inline

              if not chosen_inline_name and not chosen_attachment:
                  print(f"Could not match any attachment for row ID {r['ID']}.", file=sys.stderr)
                  sys.exit(1)

              source_name = chosen_inline_name or (chosen_attachment["name"] if chosen_attachment else attachment_hint)
              canonical_name = canonical_filename(
                  issue_seed,
                  idx,
                  r.get("Topic", ""),
                  r.get("ID", f"row{idx}"),
                  source_name or f"row{idx}.csv",
                  r.get("Time Unit", ""),
                  r.get("Energy Unit", ""),
              )
              dest = raw_dir / canonical_name

              have = False
              if chosen_inline_name:
                  print(f"Writing inline file '{chosen_inline_name}' -> {dest}")
                  dest.parent.mkdir(parents=True, exist_ok=True)
                  with open(dest, "w", newline="") as f:
                      f.write(inline_files[chosen_inline_name])
                  have = True
              elif chosen_attachment:
                  print(f"Attempting download '{chosen_attachment['name']}' -> {dest}")
                  have = _download_attachment(chosen_attachment, dest)

              r.pop("__attachment_hint__", None)
              r["Filename"] = canonical_name

              if not have:
                  print(f"Could not obtain '{canonical_name}'.", file=sys.stderr)
                  print("Either attach the CSV or embed it as a code block like:", file=sys.stderr)
                  print("```csv filename=" + (source_name or canonical_name) + "\\n<your csv content>\\n```", file=sys.stderr)
                  sys.exit(1)

          # ---------- Append/update DB rows ----------
          if SUBMISSION_COL not in df.columns:
              df[SUBMISSION_COL] = pd.Series(dtype="string")
          elif str(df[SUBMISSION_COL].dtype) != "string":
              df[SUBMISSION_COL] = df[SUBMISSION_COL].astype("string")

          if not {"ProcessedAt","Peak_kW","Area_kJ","UID","Concise ID"}.issubset(df.columns):
              for c in ["ProcessedAt","UID","Concise ID"]:
                  if c not in df.columns: df[c] = pd.Series(dtype="string")
              for c in ["Peak_kW","Area_kJ"]:
                  if c not in df.columns: df[c] = pd.Series(dtype="float64")

          # Submission keys ensure reruns of the same issue rows update instead of duplicating
          if issue_number:
              prefix = f"issue-{issue_number}"
          elif run_id:
              prefix = f"run-{run_id}"
          else:
              prefix = "manual"

          prepared_rows = []
          for idx, r in enumerate(rows, start=1):
              r = dict(r)
              r[SUBMISSION_COL] = f"{prefix}-row-{idx}"
              prepared_rows.append(r)

          existing_keys = set(
              key
              for key in (
                  str(val).strip()
                  for val in df[SUBMISSION_COL].astype(str).tolist()
              )
              if key and key.lower() != "nan"
          )

          to_add = []
          for r in prepared_rows:
              key = str(r.get(SUBMISSION_COL,"" )).strip()
              if key and key in existing_keys:
                  mask = (df[SUBMISSION_COL] == key)
                  for k in ["ID","Scource in IDEEE","Time Unit","Energy Unit","Topic","Filename"]:
                      df.loc[mask, k] = r[k]
              else:
                  to_add.append(r)
                  if key:
                      existing_keys.add(key)

          if to_add:
              df = pd.concat([df, pd.DataFrame(to_add)], ignore_index=True)

          df.to_csv(csv_path, index=False)
          PY

      - name: Run HRR validation
        if: ${{ steps.mode.outputs.mode == 'validation' }}
        id: validation_run
        continue-on-error: true
        run: |
          python - << 'PY'
          import os, subprocess, sys
          import matplotlib; matplotlib.use("Agg")
          script = (
            'hrr_chat.py' if os.path.exists('hrr_chat.py')
            else ('hrrkit_excel.py' if os.path.exists('hrrkit_excel.py') else None)
          )
          if not script:
            print("Error: neither hrr_chat.py nor hrrkit_excel.py found", file=sys.stderr)
            sys.exit(1)
          sys.exit(subprocess.call([sys.executable, script,
            "--database","database.csv","--raw","raw_files","--base","hrr_database",
            "--quantile","0.90","--validate-only","--validation-report","validation_report.json"]))
          PY

      - name: Summarize validation results
        if: ${{ steps.mode.outputs.mode == 'validation' }}
        id: validation_summary
        run: |
          python - <<'PY'
          import json, os
          from pathlib import Path

          report_path = Path('validation_report.json')
          lines = ['### HRR validation report']
          status = 'error'
          if not report_path.exists():
              lines.append('')
              lines.append('_Validator did not produce a report._')
          else:
              data = json.loads(report_path.read_text())
              status = data.get('overall_status', 'error')
              rows = data.get('rows') or []
              lines.append('')
              lines.append(f"*Overall status:* **{status.upper()}**")
              if not rows:
                  lines.append('')
                  lines.append('No pending rows were found in database.csv.')
              else:
                  for row in rows:
                      indicator = '✅' if row.get('status') == 'ok' else '❌'
                      rid = str(row.get('id') or row.get('row_index'))
                      topic = row.get('topic') or '(topic missing)'
                      lines.append('')
                      lines.append(f"{indicator} Row ID {rid} ({topic})")
                      errors = row.get('errors') or []
                      warnings = row.get('warnings') or []
                      for err in errors:
                          lines.append(f"    - {err}")
                      for warn in warnings:
                          lines.append(f"    - warning: {warn}")

          summary = '\n'.join(lines).strip() + '\n'
          Path('validation_summary.md').write_text(summary, encoding='utf-8')
          with open(os.environ['GITHUB_OUTPUT'], 'a', encoding='utf-8') as fh:
              fh.write(f"status={status}\n")
              fh.write("summary<<EOF\n")
              fh.write(summary)
              fh.write("EOF\n")
          PY

      - name: Update validation label
        if: ${{ steps.mode.outputs.mode == 'validation' }}
        uses: actions/github-script@v7
        with:
          script: |
            const issueNumber = Number('${{ steps.payload.outputs.number }}');
            const status = '${{ steps.validation_summary.outputs.status }}';
            const labelName = 'hrr-validated';
            if (status === 'success') {
              await github.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                labels: [labelName],
              });
            } else {
              try {
                await github.rest.issues.removeLabel({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  name: labelName,
                });
              } catch (error) {
                // ignore if label absent
              }
            }

      - name: Comment validation result
        if: ${{ steps.mode.outputs.mode == 'validation' }}
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const issueNumber = Number('${{ steps.payload.outputs.number }}');
            const status = '${{ steps.validation_summary.outputs.status }}';
            let summary = 'Validation summary unavailable.\n';
            try {
              summary = fs.readFileSync('validation_summary.md', 'utf-8');
            } catch (error) {
              // keep fallback summary
            }
            const nextStep = status === 'success'
              ? '\n\n✅ Validation passed. Comment **`/intake-commit`** to run Phase 2 (processing + commit).'
              : '\n\nPlease address the issues above, then comment **`/validate`** to rerun Phase 1.';
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: summary + nextStep,
            });

      - name: Run HRR processor
        if: ${{ steps.mode.outputs.mode == 'process' }}
        id: process_run
        run: |
          python - << 'PY'
          import os, subprocess, sys
          import matplotlib; matplotlib.use("Agg")
          script = (
            'hrr_chat.py' if os.path.exists('hrr_chat.py')
            else ('hrrkit_excel.py' if os.path.exists('hrrkit_excel.py') else None)
          )
          if not script:
            print("Error: neither hrr_chat.py nor hrrkit_excel.py found", file=sys.stderr)
            sys.exit(1)
          sys.exit(subprocess.call([sys.executable, script,
            "--database","database.csv","--raw","raw_files","--base","hrr_database","--quantile","0.90"]))
          PY

      - name: Ensure output dir for artifact
        if: ${{ steps.mode.outputs.mode == 'process' }}
        run: mkdir -p hrr_database

      - name: Upload outputs (artifact)
        if: ${{ steps.mode.outputs.mode == 'process' }}
        uses: actions/upload-artifact@v4
        with:
          name: hrr-outputs-issue-${{ steps.payload.outputs.number }}
          path: |
            hrr_database/**
            database.csv
          if-no-files-found: warn
          retention-days: 10

      - name: Commit changes (processing phase)
        if: ${{ steps.mode.outputs.mode == 'process' }}
        shell: bash
        run: |
          set -e
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --global --add safe.directory "$GITHUB_WORKSPACE"

          if [ -n "$(git status --porcelain)" ]; then
            git add -A
            git commit -m "HRR intake (issue #${{ steps.payload.outputs.number }}): processed inputs [skip ci]"
            git push
          else
            echo "No changes to commit."
          fi

      - name: Clear validation label after processing
        if: ${{ always() && steps.mode.outputs.mode == 'process' }}
        uses: actions/github-script@v7
        with:
          script: |
            const issueNumber = Number('${{ steps.payload.outputs.number }}');
            const labelName = 'hrr-validated';
            try {
              await github.rest.issues.removeLabel({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                name: labelName,
              });
            } catch (error) {
              // ignore
            }

      - name: Comment processing result
        if: ${{ always() && steps.mode.outputs.mode == 'process' }}
        uses: actions/github-script@v7
        with:
          script: |
            const num = Number('${{ steps.payload.outputs.number }}');
            const artifactName = `hrr-outputs-issue-${num}`;
            const succeeded = '${{ steps.process_run.outcome }}' === 'success';
            const lines = [];
            if (succeeded) {
              lines.push('✅ HRR processing (Phase 2) completed.');
              lines.push('');
              lines.push(`- Artifact: **${artifactName}**`);
              lines.push('- Results were committed to the repository.');
              lines.push('');
              lines.push('Need to ingest more data? Update the issue and rerun Phase 1 with **`/validate`**.');
            } else {
              lines.push('❌ HRR processing (Phase 2) failed.');
              lines.push('');
              lines.push('Check the workflow logs for details, address the problem, then rerun Phase 1 with **`/validate`**.');
            }
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: num,
              body: lines.join('\n'),
            });
